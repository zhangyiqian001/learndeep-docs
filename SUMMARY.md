# Table of contents

* [Introduction](README.md)
* [1. 开山模型](chapter1/README.md)
  * [Playing Atari with Deep Reinforcement Learning](chapter1/article/Playing+Atari+with+Deep+Reinforcement+Learning.md)
  
  * [FCN:Fully Convolutional Networks for Semantic Segmentation](chapter1/article/Fully+Convolutional+Networks+for+Semantic+Segmentation.md)
  
  * [U-Net:Convolutional Networks for Biomedical Image Segmentation](chapter1/article/Convolutional+Networks+for+Biomedical+Image+Segmentation.md)
  
  * [GAN:Generative Adversarial Nets](chapter1/article/Generative+Adversarial+Nets.md)
  
  * [Attention Is All You Need](chapter1/article/Attention+Is+All+You+Need.md)
  
  * [GPT-1:Improving Language Understanding by Generative Pre-Training](chapter1/article/Improving+Language+Understanding+by+Generative+Pre-Training.md)
  
  * [InstructGPT:Training language models to follow instructions with human feedback](chapter1/article/Training+language+models+to+follow+instructions+with+human+feedback.md)
  
  * [BERT:Pre-training of Deep Bidirectional Transformers for Language Understanding](chapter1/article/Pre-training+of+Deep+Bidirectional+Transformers+for+Language+Understanding.md)
  
  * [BART:Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension](chapter1/article/Denoising+Sequence-to-Sequence+Pre-training+for+Natural+Language+Generation,+Translation,+and+Comprehension.md)
  
  * [T5:Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](chapter1/article/Exploring+the+Limits+of+Transfer+Learning+with+a+Unified+Text-to-Text+Transformer.md)
  
  * [ELMo:Deep contextualized word representations](chapter1/article/Deep+contextualized+word+representations.md)
  
  * [ViT:AN IMAGE IS WORTH 16X16 WORDS_ TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE](chapter1/article/AN+IMAGE+IS+WORTH+16X16+WORDS+TRANSFORMERS+FOR+IMAGE+RECOGNITION+AT+SCALE.md)
  
  * [Distilling the Knowledge in a Neural Network](chapter1/article/Distilling+the+Knowledge+in+a+Neural+Network.md)
  
  * [DeiT:Training data-efficient image transformers & distillation through attention](chapter1/article/Training+data-efficient+image+transformers+++distillation+through+attention.md)
  
  * [Swin Transformer:Hierarchical Vision Transformer using Shifted Windows](chapter1/article/Hierarchical+Vision+Transformer+using+Shifted+Windows.md)
  
  * [DETR:End-to-End Object Detection with Transformers](chapter1/article/End-to-End+Object+Detection+with+Transformers.md)
  
  * [CLIP:Learning Transferable Visual Models From Natural Language Supervision](chapter1/article/Learning+Transferable+Visual+Models+From+Natural+Language+Supervision.md)
  
  * [VAE:Auto-Encoding Variational Bayes](chapter1/article/Auto-Encoding+Variational+Bayes.md)
  
  * [VQ-VAE:Neural Discrete Representation Learning](chapter1/article/Neural+Discrete+Representation+Learning.md)
  
  * [VQ-VAE2:Generating Diverse High-Fidelity Images with VQ-VAE-2](chapter1/article/Generating+Diverse+High-Fidelity+Images+with+VQ-VAE-2.md)
  
  * [KAN:Kolmogorov–Arnold Networks](chapter1/article/Kolmogorov-Arnold+Networks.md)
  
  * [Pixel RNN:Pixel Recurrent Neural Networks](chapter1/article/Pixel+Recurrent+Neural+Networks.md)
  
  * [Conditional Image Generation with PixelCNN Decoders](chapter1/article/Conditional+Image+Generation+with+PixelCNN+Decoders.md)
  
  * [GQA:Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints](chapter1/article/Training+Generalized+Multi-Query+Transformer+Models+from+Multi-Head+Checkpoints.md)
  
  * [FlashAttention:Fast and Memory-Efficient Exact Attention with IO-Awareness](chapter1/article/Fast+and+Memory-Efficient+Exact+Attention+with+IO-Awareness.md)
  
  * [Efficient Memory Management for Large Language Model Serving with PagedAttention](chapter1/article/Efficient+Memory+Management+for+Large+Language+Model+Serving+with+PagedAttention.md)
  
* [2. 自然语言处理](chapter2/README.md)
* [3. 计算机视觉](chapter3/README.md)
  * [DDPM:Denoising Diffusion Probabilistic Models](chapter3/article/Denoising+Diffusion+Probabilistic+Models.md)

  * [DDIM:DENOISING DIFFUSION IMPLICIT MODELS](chapter3/article/DENOISING+DIFFUSION+IMPLICIT+MODELS.md)

  * [CDM:Diffusion Models Beat GANs on Image Synthesis](chapter3/article/Diffusion+Models+Beat+GANs+on+Image+Synthesis.md)

  * [SCORE-BASED GENERATIVE MODELING THROUGH STOCHASTIC DIFFERENTIAL EQUATIONS](chapter3/article/SCORE-BASED+GENERATIVE+MODELING+THROUGH+STOCHASTIC+DIFFERENTIAL+EQUATIONS.md)

  * [CDM:CLASSIFIER-FREE DIFFUSION GUIDANCE](chapter3/article/CLASSIFIER-FREE+DIFFUSION+GUIDANCE.md)

  * [RePaint:Inpainting using Denoising Diffusion Probabilistic Models](chapter3/article/Inpainting+using+Denoising+Diffusion+Probabilistic+Models.md)

  * [Stable Diffusion:High-Resolution Image Synthesis with Latent Diffusion Models](chapter3/article/High-Resolution+Image+Synthesis+with+Latent+Diffusion+Models.md)

  * [Semi-Parametric Neural Image Synthesis](chapter3/article/Semi-Parametric+Neural+Image+Synthesis.md)

  * [Stable Video Diffusion:Scaling Latent Video Diffusion Models to Large Datasets](chapter3/article/Scaling+Latent+Video+Diffusion+Models+to+Large+Datasets.md)

  * [DiT:Scalable Diffusion Models with Transformers](chapter3/article/Scalable+Diffusion+Models+with+Transformers.md)

  * [Sora:A Review on Background, Technology, Limitations, and Opportunities of Large Vision Models](chapter3/article/A+Review+on+Background,+Technology,+Limitations,+and+Opportunities+of+Large+Vision+Models.md)

  * [Segment Anything](chapter3/article/Segment+Anything.md)

  * [ControlNet:Adding Conditional Control to Text-to-Image Diffusion Models](chapter3/article/Adding+Conditional+Control+to+Text-to-Image+Diffusion+Models.md)

  * [T2I-Adapter:Learning Adapters to Dig out More Controllable Ability for Text-to-Image Diffusion Models](chapter3/article/Learning+Adapters+to+Dig+out+More+Controllable+Ability+for+Text-to-Image+Diffusion+Models.md)

  * [IP-Adapter:Text Compatible Image Prompt Adapter for Text-to-Image Diffusion Models](chapter3/article/Text+Compatible+Image+Prompt+Adapter+for+Text-to-Image+Diffusion+Models.md)

  * [Imagen:Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding](chapter3/article/Photorealistic+Text-to-Image+Diffusion+Models+with+Deep+Language+Understanding.md)

  * [DALL·E:Zero-Shot Text-to-Image Generation](chapter3/article/Zero-Shot+Text-to-Image+Generation.md)

  * [DALL·E2:unCLIP:Hierarchical Text-Conditional Image Generation with CLIP Latents](chapter3/article/Hierarchical+Text-Conditional+Image+Generation+with+CLIP+Latents.md)

  * [DALL·E3:Improving Image Captioning with Better Use of Captions](chapter3/article/Improving+Image+Captioning+with+Better+Use+of+Captions.md)

  * [VQ-GAN:Taming Transformers for High-Resolution Image Synthesis](chapter3/article/Taming+Transformers+for+High-Resolution+Image+Synthesis.md)

* [4. 强化学习](chapter4/README.md)
* [5. 大模型微调](chapter5/README.md)
  * [Adapter tuning:Parameter-Effificient Transfer Learning for NLP](chapter5/article/Parameter-Effificient+Transfer+Learning+for+NLP.md)

  * [Prefix-Tuning:Optimizing Continuous Prompts for Generation](chapter5/article/Optimizing+Continuous+Prompts+for+Generation.md)

  * [Prompt Tuning:The Power of Scale for Parameter-Effificient Prompt Tuning](chapter5/article/The+Power+of+Scale+for+Parameter-Effificient+Prompt+Tuning.md)

  * [P-Tuning:GPT Understands, Too](chapter5/article/GPT+Understands,+Too.md)

  * [P-Tuning v2:Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks](chapter5/article/Prompt+Tuning+Can+Be+Comparable+to+Fine-tuning+Universally+Across+Scales+and+Tasks.md)

  * [LoRA:Low-rank adaptation of large language models](chapter5/article/Low-rank+adaptation+of+large+language+models.md)

  * [IA3：Few-Shot Parameter-Effificient Fine-Tuning is Better and Cheaper than In-Context Learning](chapter5/article/Few-Shot+Parameter-Effificient+Fine-Tuning+is+Better+and+Cheaper+than+In-Context+Learning.md)


* [6. 参考文献](chapter6/README.md)
* [7. 贡献](chapter7/README.md)
  