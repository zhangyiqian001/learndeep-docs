stable_video_diffusion

# 摘要

我们提出了Stable Video Diffusion（SVD）一个潜在的视频扩散模型，用于高分辨率，最先进的文本到视频和图像到视频的生成。近年来，通过插入时间层并在小的、高质量的视频数据集上进行微调，训练用于二维图像合成的潜在扩散模型已转化为生成式视频模型。然而，文献中的训练方法差异很大，该领域尚未就管理视频数据的统一策略达成一致。在本文中，我们确定并评估了视频LDMs成功训练的三个不同阶段：文本到图像的预训练、视频预训练和高质量的视频微调。此外，我们还证明了需要一个精心策划的预训练数据集来生成高质量的视频，并提出了一个系统的管理过程来训练一个强大的基础模型，包括字幕和过滤策略。然后，我们探讨了微调我们的基础模型对高质量数据的影响，并训练了一个可以与闭源视频生成竞争的文本到视频模型。我们还展示了，我们的基础模型为下游任务提供了一个强大的动态表示，如图像到视频的生成和对摄像机运动特定的LoRA模块的适应性。最后，我们证明了我们的模型提供了一个强大的多视图三维先验，并可以作为微调多视图扩散模型的基础，该模型以前馈方式联合生成对象的多个视图，在其计算预算的一小部分上优于基于图像的方法。

## 导言



